---
title: '计算机如何表示文字'
description: '众所周知，计算机使用二进制来储存信息，文字也不例外，文字通过编码转换成二进制储存在计算机中。你是否经历过打开一个文件出来全都是乱码的时候，这便是编码惹得祸。'
pubDate: '2024-5-14'
cover: './totoro.jpg'
---
# 计算机中的二进制
## 什么是二进制

计算机是处理数字的机器，计算机的核心功能是处理数字信息得以实现的。现如今，通过数字信号和模拟信号的相互转换，我们得到了计算机丰富的视听上的体验。

计算机中的数字计数不同与现实世界的计数，计算机采用二进制计数，而我们世界采用十进制。我们用阿拉伯数字，每当数字“满十”后便向前进一位，用零和一这两个阿拉伯数字的有序数列来表示10。

$$ 9 + 1 = 10 $$

然而在计算机中，只有`0`和`1`供他们使用。在二进制的世界，数字可能看起来有点陌生。比如我们熟悉的`2`用二进制表示为`010`, 1、2、3、4对应的二进制为`001`、`010` 、`011`、`100`。我们可能因为太习以为常而疏忽的“个位”，“十位”，“百位”，之所以是个、十、百、是因为10的零次幂是1，10的一次幂是10，10的二次幂是100。按照对应关系，二进制中相应的位置用十进制的角度来看便是一、二、四，所以`001`是一、`010`是二、`100`是四。`011`便是二加一等于三。

这时候可能有观众要问了，why computer use binary number system?

二进制只需要两种对立的状态，物理实现上肯定要比更高进制的数字要简单。例如电压的高低，晶体管的开和关。

# 用二进制来表示文字
## ASCII

**ASCII**全名为*American Standard Code for Information Interchange*，是一种编码规范，使用这种编码的计算机可以使用特定的二进制编码来表示对应的字母或符号，从而让计算机可以储存英文文本。计算机上的所有东西都要以二进制的形式进行储存，而具体如何转换成二进制，便是编码。两台计算机只有使用相同的编码才能不混乱的储存同一种信息。储存和显示英语的规范ASCII应运而生。ASCII使用8位二进制数来表示字符（也可以说7位，因为最高位总是零），表示128位不同的字符，其中控制字符33个，显示字符95个。

[ASCII码表链接](https://www.asciitable.com/)

使用ASCII使电脑能够处理现代英语，但对其他语言就无可奈何了。

## Unicode

Unicode，中文名称称为统一码。更多介绍可以访问[维基百科](https://zh.wikipedia.org/wiki/Unicode)。

Unicode尝试使用一个通用标准来显示世界上所有的符号，无论是，目前Unicode主要编码实现为UTF-8和UTF-16。Unicode的UCS-2版本字符集，使用16位编码构成基本多文种平面，以满足各种语言使用。未来的UCS-4将会使用31一位字符集，加上恒为零的首位，共计4字节。

Unicode在字符集上有了统一的编码，但在实现上略有不同

为了节省储存空间，作为Unicode的一种实现采用了额外的特殊处理实现的UTF-8，采用了变长编码的方式来储存Unicode。

UTF-8向下兼容ASCII，ASCII可以表示的字符在UTF-8中和ASCII的编码一样，同样的占用7位+1位为零的首位。UTF-8对首位加以利用，来区分是否可以用一个Byte表示。当首位为0时，及传统的ASCII字符，用一个Byte表示。如果首位为1，则表示需要用多个Byte表示，具体需要多少个Byte编码，则利用首位之后的位来判断。Unicode可以用1到4个Byte来表示Unicode编码。下面是一个Unicode码到UTF实际编码的对应表格

| Unicode编码范围 | Byte 1 | Byte 2 | Byte 3 | Byte 4|
| --- | --- | --- | --- | --- |
| U+0000 - U+007F | 0xxxxxx|
| U+0080 - U+07FF | 110xxxxx | 10xxxxxx | 
| U+0800 - U+FFFF| 1110xxxx | 10xxxxxx | 10xxxxxx
| U+10000 - U+10FFFF | 11110xxx | 10xxxxxx | 10xxxxxx | 10xxxxxx